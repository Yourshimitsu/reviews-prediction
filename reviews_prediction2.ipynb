{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrGFZoFESBdV",
        "outputId": "1952addc-3709-487b-f0d5-0d4228100c45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "import math\n",
        "import random\n",
        "from collections import Counter\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DALtGz1BTO0i",
        "outputId": "98df554f-003c-4efa-f389-535579e2ad81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Распределение классов:\n",
            "overall\n",
            "5.0    284435\n",
            "4.0     88407\n",
            "3.0     46546\n",
            "1.0     29138\n",
            "2.0     22830\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\n",
        "    \"/content/drive/MyDrive/colab/Video_Games_5_part0.csv\",\n",
        "    on_bad_lines=\"skip\"\n",
        ")\n",
        "df = df.dropna(subset=[\"reviewText\", \"overall\"])\n",
        "\n",
        "class_counts = df['overall'].value_counts()\n",
        "print(f\"Распределение классов:\\n{class_counts}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6DrWGugqmqC",
        "outputId": "ba57221c-8d0b-44dd-fb67-86ba0795e814"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gyqanWSTxYq",
        "outputId": "26f3005c-6421-4f1d-aeb0-cb7e8b8a72c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "X = df[\"reviewText\"].astype(str)\n",
        "y = df[\"overall\"].astype(int)\n",
        "\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.15,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp,\n",
        "    test_size=0.15 / 0.85,\n",
        "    random_state=42,\n",
        "    stratify=y_temp\n",
        ")\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQeppm3UWAXw"
      },
      "source": [
        "Я скачал word2vec из fasttext и оставил вектора только для слов, что есть в train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1GluzYXkX6n"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(\"/content/ft_subset.pkl\", \"wb\") as f:\n",
        "    pickle.dump((word2vec, dim), f, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qihZ9GOOaMtr"
      },
      "source": [
        "2. Word2Vec + LSTM(с кастомным лоссом)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsZtMLH1aODW"
      },
      "source": [
        "$$\n",
        "\\textbf{Идея 1 (учёт упорядоченности классов через soft-label).}\\quad\n",
        "q_{y,i}=\\frac{\\exp(-\\tau\\,|i-y|)}{\\sum\\limits_{j=1}^{5}\\exp(-\\tau\\,|j-y|)},\\qquad\n",
        "L_1(x,y)=\\sum_{i=1}^{5} q_{y,i}\\,(-\\log p_i).\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\textbf{Идея 2 (учёт несбалансированности классов).}\\quad\n",
        "n_k=\\#\\{(x_j,y_j)\\ \\text{в train}:\\ y_j=k\\},\\qquad\n",
        "w_k=\\frac{n}{n_k},\\qquad\n",
        "\\qquad\n",
        "L(x,y)= w_y \\cdot L_1(x,y)=w_y\\sum_{i=1}^{5} q_{y,i}\\,(-\\log p_i).\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koMF2yeclAMG",
        "outputId": "164a4c5e-f232-48f7-c461-e4adac3a7692"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "300\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"/content/drive/MyDrive/colab/ft_subset.pkl\", \"rb\") as f:\n",
        "    word2vec, dim = pickle.load(f)\n",
        "print(dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7nE633soFK2"
      },
      "source": [
        "embedding hits: 98649 / 166416\n",
        "\n",
        "\n",
        "Для слишком большого числа слов нет эмбединга я добавлю CNN по буквам на вход будет подаваться вектор полученный конкатенацией эмбединга и CNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF8MAIUVre_I"
      },
      "source": [
        "Токенизация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oMPOxfVrGix",
        "outputId": "06ec47d8-1b28-428f-e4bd-45ad17e820b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(91016, 39)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def simple_word_tokenize(text: str):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z0-9']+\", \" \", text)\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "PAD = \"<pad>\"\n",
        "UNK = \"<unk>\"\n",
        "\n",
        "def build_word_vocab(texts, min_freq=2, max_vocab=200000):\n",
        "    from collections import Counter\n",
        "    c = Counter()\n",
        "    for t in texts:\n",
        "        c.update(simple_word_tokenize(t))\n",
        "    items = [(w,f) for w,f in c.items() if f >= min_freq]\n",
        "    items.sort(key=lambda x: x[1], reverse=True)\n",
        "    items = items[:max_vocab]\n",
        "\n",
        "    stoi = {PAD: 0, UNK: 1}\n",
        "    for w,_ in items:\n",
        "        if w not in stoi:\n",
        "            stoi[w] = len(stoi)\n",
        "    itos = {i:w for w,i in stoi.items()}\n",
        "    return stoi, itos, c\n",
        "\n",
        "CPAD = \"<cpad>\"\n",
        "CUNK = \"<cunk>\"\n",
        "\n",
        "def build_char_vocab():\n",
        "    chars = list(\"abcdefghijklmnopqrstuvwxyz0123456789'\")\n",
        "    stoi = {CPAD: 0, CUNK: 1}\n",
        "    for ch in chars:\n",
        "        stoi[ch] = len(stoi)\n",
        "    itos = {i:ch for ch,i in stoi.items()}\n",
        "    return stoi, itos\n",
        "\n",
        "word_stoi, word_itos, word_freq = build_word_vocab(X_train.tolist(), min_freq=2, max_vocab=200000)\n",
        "char_stoi, char_itos = build_char_vocab()\n",
        "\n",
        "len(word_stoi), len(char_stoi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNN6VYcUr8xx"
      },
      "source": [
        "Матрица эмбедингов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0T-37werqaq",
        "outputId": "2037d6df-01a0-4ba2-d5ea-b5caeb6359ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(66436, 91016)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_vec(word):\n",
        "    try:\n",
        "        if word in word2vec:\n",
        "            v = word2vec[word]\n",
        "            return np.asarray(v, dtype=np.float32)\n",
        "    except TypeError:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "emb_dim = dim\n",
        "\n",
        "embedding_matrix = np.random.normal(0, 0.05, size=(len(word_stoi), emb_dim)).astype(np.float32)\n",
        "embedding_matrix[word_stoi[PAD]] = np.zeros(emb_dim, dtype=np.float32)\n",
        "\n",
        "hits = 0\n",
        "for w, idx in word_stoi.items():\n",
        "    if w in (PAD, UNK):\n",
        "        continue\n",
        "    v = get_vec(w)\n",
        "    if v is not None and v.shape[0] == emb_dim:\n",
        "        embedding_matrix[idx] = v\n",
        "        hits += 1\n",
        "\n",
        "hits, len(word_stoi)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDBI1AGCsAoP"
      },
      "source": [
        "Паддинг слов и символов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyx96mKqsDIJ"
      },
      "outputs": [],
      "source": [
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, texts, labels, word_stoi, char_stoi):\n",
        "        self.texts = list(texts)\n",
        "        self.labels = list(labels)\n",
        "        self.word_stoi = word_stoi\n",
        "        self.char_stoi = char_stoi\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def encode_word(self, w):\n",
        "        return self.word_stoi.get(w, self.word_stoi[UNK])\n",
        "\n",
        "    def encode_chars(self, w):\n",
        "        return [self.char_stoi.get(ch, self.char_stoi[CUNK]) for ch in w]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        text = self.texts[i]\n",
        "        tokens = simple_word_tokenize(text)\n",
        "        if len(tokens) == 0:\n",
        "            tokens = [UNK]\n",
        "\n",
        "        y = int(self.labels[i]) - 1  # 1..5 -> 0..4\n",
        "\n",
        "        word_ids = [self.encode_word(w) for w in tokens]\n",
        "        char_ids = [self.encode_chars(w) for w in tokens]\n",
        "\n",
        "        return word_ids, char_ids, y\n",
        "\n",
        "def make_collate_fn(max_tokens=200, max_char_len=16):\n",
        "    def collate(batch):\n",
        "        ys = torch.tensor([b[2] for b in batch], dtype=torch.long)\n",
        "\n",
        "        word_seqs = [b[0][:max_tokens] for b in batch]\n",
        "        char_seqs = [b[1][:max_tokens] for b in batch]\n",
        "\n",
        "        lengths = torch.tensor([len(s) for s in word_seqs], dtype=torch.long)\n",
        "        T = int(lengths.max().item()) if len(batch) > 0 else 0\n",
        "\n",
        "        xw = torch.full((len(batch), T), fill_value=word_stoi[PAD], dtype=torch.long)\n",
        "        xc = torch.full((len(batch), T, max_char_len), fill_value=char_stoi[CPAD], dtype=torch.long)\n",
        "\n",
        "        for i,(ws, cs) in enumerate(zip(word_seqs, char_seqs)):\n",
        "            xw[i, :len(ws)] = torch.tensor(ws, dtype=torch.long)\n",
        "            for t, ch_list in enumerate(cs):\n",
        "                ch_list = ch_list[:max_char_len]\n",
        "                if len(ch_list) > 0:\n",
        "                    xc[i, t, :len(ch_list)] = torch.tensor(ch_list, dtype=torch.long)\n",
        "\n",
        "        return xw, xc, lengths, ys\n",
        "    return collate\n",
        "\n",
        "train_ds = ReviewDataset(X_train, y_train, word_stoi, char_stoi)\n",
        "test_ds  = ReviewDataset(X_test, y_test, word_stoi, char_stoi)\n",
        "val_ds = ReviewDataset(X_val, y_val, word_stoi, char_stoi)\n",
        "\n",
        "collate_fn = make_collate_fn(max_tokens=200, max_char_len=16)\n",
        "\n",
        "persistent_workers=True\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=0, collate_fn=collate_fn, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds, batch_size=128, shuffle=False, num_workers=0, collate_fn=collate_fn, pin_memory=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=128, shuffle=False, num_workers=0, collate_fn=collate_fn, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQibrkztsKKr"
      },
      "source": [
        "char-CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-cbIsyJsLoy"
      },
      "outputs": [],
      "source": [
        "class CharCNN(nn.Module):\n",
        "    def __init__(self, char_vocab_size, char_emb_dim=32, out_dim=64, kernel_size=3, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.char_emb = nn.Embedding(char_vocab_size, char_emb_dim, padding_idx=char_stoi[CPAD])\n",
        "        self.conv = nn.Conv1d(char_emb_dim, out_dim, kernel_size=kernel_size, padding=kernel_size//2)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, xc):\n",
        "        B, T, W = xc.shape\n",
        "        x = self.char_emb(xc)           # (B,T,W,E)\n",
        "        x = x.view(B*T, W, -1).transpose(1, 2)  # (B*T,E,W)\n",
        "        x = F.relu(self.conv(x))        # (B*T, out_dim, W)\n",
        "        x = torch.max(x, dim=2).values  # (B*T, out_dim)\n",
        "        x = self.dropout(x)\n",
        "        x = x.view(B, T, -1)            # (B,T,out_dim)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4h7kw3XsQvv"
      },
      "source": [
        "Word2Vec + char-CNN -> BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQujTQpRsXF6"
      },
      "outputs": [],
      "source": [
        "class W2VCharBiLSTM(nn.Module):\n",
        "    def __init__(self, embedding_matrix, char_vocab_size,\n",
        "                 char_emb_dim=32, char_out_dim=64,\n",
        "                 lstm_hidden=256, lstm_layers=1,\n",
        "                 num_classes=5, dropout=0.2):\n",
        "        super().__init__()\n",
        "        V, D = embedding_matrix.shape\n",
        "\n",
        "        self.word_emb = nn.Embedding(V, D, padding_idx=word_stoi[PAD])\n",
        "        self.word_emb.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        self.word_emb.weight.requires_grad = False\n",
        "\n",
        "        self.charcnn = CharCNN(char_vocab_size, char_emb_dim=char_emb_dim, out_dim=char_out_dim, dropout=dropout)\n",
        "\n",
        "        in_dim = D + char_out_dim\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=in_dim,\n",
        "            hidden_size=lstm_hidden,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(2*lstm_hidden, num_classes)\n",
        "\n",
        "    def forward(self, xw, xc, lengths):\n",
        "        # xw: (B,T), xc: (B,T,W), lengths: (B,)\n",
        "        we = self.word_emb(xw)          # (B,T,D)\n",
        "        ce = self.charcnn(xc)           # (B,T,C)\n",
        "        x = torch.cat([we, ce], dim=-1) # (B,T,D+C)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        packed_out, (h_n, c_n) = self.lstm(packed)\n",
        "\n",
        "        # h_n: (num_layers*2, B, H). Берём последний слой, оба направления\n",
        "        h_fwd = h_n[-2]   # (B,H)\n",
        "        h_bwd = h_n[-1]   # (B,H)\n",
        "        h = torch.cat([h_fwd, h_bwd], dim=-1)  # (B,2H)\n",
        "\n",
        "        h = self.dropout(h)\n",
        "        logits = self.fc(h)             # (B,5)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bPTGCYSscN6"
      },
      "source": [
        "Лосс"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Voao_C1asdea"
      },
      "outputs": [],
      "source": [
        "class OrdinalImbalanceLoss(nn.Module):\n",
        "    def __init__(self, class_counts, num_classes=5, tau=1.0, eps=1e-8, normalize_weights=True):\n",
        "        super().__init__()\n",
        "        n = float(sum(class_counts))\n",
        "\n",
        "        w = torch.tensor([n / (c + eps) for c in class_counts], dtype=torch.float32)\n",
        "        if normalize_weights:\n",
        "            w = w / w.mean().clamp_min(eps)\n",
        "        self.register_buffer(\"class_w\", w)\n",
        "\n",
        "        dist = torch.zeros(num_classes, num_classes, dtype=torch.float32)\n",
        "        for y in range(num_classes):\n",
        "            for i in range(num_classes):\n",
        "                dist[y, i] = abs(i - y)\n",
        "\n",
        "        q = torch.softmax(-tau * dist, dim=1)\n",
        "        self.register_buffer(\"q\", q)\n",
        "\n",
        "    def forward(self, logits, y):\n",
        "        logp = F.log_softmax(logits, dim=1)      # (B,5)\n",
        "        qy = self.q[y]                           # (B,5)\n",
        "        l1 = (qy * (-logp)).sum(dim=1)           # (B,)\n",
        "        w = self.class_w[y]                      # (B,)\n",
        "        return (w * l1).mean()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_WNtw8OsrT5"
      },
      "source": [
        "Почитаем по классам количество"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9-chMFLsvAz",
        "outputId": "ad38ea6c-e5b3-4a9b-eae7-867566974f9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[20396, 15981, 32582, 61885, 199104]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "counts = np.bincount((y_train.values - 1), minlength=5).tolist()\n",
        "counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHWtkM1bsyuf"
      },
      "source": [
        "Модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qD8YZNIMs4t-"
      },
      "outputs": [],
      "source": [
        "model = W2VCharBiLSTM(\n",
        "    embedding_matrix=embedding_matrix,\n",
        "    char_vocab_size=len(char_stoi),\n",
        "    char_emb_dim=32,\n",
        "    char_out_dim=64,\n",
        "    lstm_hidden=256,\n",
        "    lstm_layers=1,\n",
        "    dropout=0.2\n",
        ").to(device)\n",
        "\n",
        "criterion = OrdinalImbalanceLoss(class_counts=counts, num_classes=5).to(device)\n",
        "optimizer = torch.optim.Adam([p for p in model.parameters() if p.requires_grad], lr=1e-3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MWcLVZdtYpk"
      },
      "source": [
        "Код для одной эпохи"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJnPPflktXBO"
      },
      "outputs": [],
      "source": [
        "train_losses, train_accs = [], []\n",
        "val_losses, val_accs = [], []\n",
        "\n",
        "def run_epoch_tqdm(model, loader, train=True):\n",
        "    model.train(train)\n",
        "    total_loss = 0.0\n",
        "    all_pred, all_true = [], []\n",
        "\n",
        "    pbar = tqdm(loader, unit=\"batch\", leave=False)\n",
        "    for xw, xc, lengths, y in pbar:\n",
        "        xw, xc, lengths, y = xw.to(device), xc.to(device), lengths.to(device), y.to(device)\n",
        "\n",
        "        if train:\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        logits = model(xw, xc, lengths)\n",
        "        loss = criterion(logits, y)\n",
        "\n",
        "        if train:\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "            optimizer.step()\n",
        "\n",
        "        bs = y.size(0)\n",
        "        total_loss += loss.item() * bs\n",
        "\n",
        "        pred = torch.argmax(logits, dim=1).detach().cpu().numpy()\n",
        "        true = y.detach().cpu().numpy()\n",
        "        all_pred.append(pred)\n",
        "        all_true.append(true)\n",
        "\n",
        "        cur_loss = total_loss / max(1, (len(np.concatenate(all_true)) if len(all_true) else bs))\n",
        "        cur_acc = (np.concatenate(all_pred) == np.concatenate(all_true)).mean()\n",
        "        pbar.set_postfix(loss=f\"{cur_loss:.4f}\", acc=f\"{cur_acc:.4f}\")\n",
        "\n",
        "    all_pred = np.concatenate(all_pred)\n",
        "    all_true = np.concatenate(all_true)\n",
        "\n",
        "    epoch_loss = total_loss / len(loader.dataset)\n",
        "    epoch_acc = (all_pred == all_true).mean()\n",
        "    return epoch_loss, epoch_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmvcRZr0tary"
      },
      "source": [
        "Обучение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "954ef74dd3ee461d9c1f343e49e6fcfc",
            "ad84469cd8ea47879a1f167d22636955",
            "1e494eabba5e4ed8b85fb3c9c38a93ce",
            "efc178b3a2484d12be00928d8144b9b5",
            "1daf0cc927994d57b515520272cdf58d",
            "c5a6f88085fa421fbeda5e9dce308aab",
            "8f09d30c1e1946efa5d5cac008ae3162",
            "46dac01e94504a1b8955244c772ae7f2",
            "ce79a79610e44f559dec6e1993669552",
            "bef8c6d5a9874d139784bfe5b792e195",
            "3726f4ab9a234f3ea6cd002e254e3c17",
            "b2192d5e5c1343da992a5bdf99bff86b",
            "eed68046415241e5b4116cbdcc287c93",
            "4793dab211484c3396c51c27b7984dfc",
            "3b68cc98c6e344feaef81919418c6b8b",
            "99507364ac6f499b821dff7e21e5d313",
            "f5912ff20ed840598de723841d103205",
            "7f72c7fe3d8547259740be0c5fb3e454",
            "52db69dae3394378b852e4ca616864f8",
            "a658653072df4d34b075dd6237c68306",
            "7815f8de8c2d45f19ec38c23fbcf3858",
            "de46c71305f841718c55f478650e8bdb",
            "d518172150784dbeb83d40c69a65995e",
            "5dcbd76690ca41c687736c63d4e8ff10",
            "7a252068bf1d46c889ec933ebd805e4e",
            "05bffe96627a4ef5b73372980e245a11",
            "c39c5914f2e34711b92ed37475785a74",
            "c663c3c2406947f19264d8579c45ef0f",
            "b66269f4f6f444dbb9765c81b3e0f49d",
            "a36de2b84c474242b3dc7ecc7a63b8e8",
            "7b804cb0774843b4b661c47e512d6e05",
            "4f18c9b98eb7432ea8e2b34e4e200c81",
            "09b2c7492a354620b0c8323b00a9749c",
            "6d5a7f19168346318659df519d2dfccc",
            "02633aee87994265ae7f4b260d77ee3c",
            "bb09beffd25f4165ba8c4c2ea08d25eb",
            "7b97a2265df74590b5d2b8e93f50891b",
            "61c29745f5df43919119f97a32ff5fe2",
            "52d9b3535a7e4a7b8fc862307c912834",
            "91ba6526bbf34750b26b3f7ac61f0464",
            "eb6143ebbdaf4f6aa59fe392a30a613d",
            "26f734a517c242a48e113cf3b1a23202",
            "95448f2ec9af4234a0186eed125924a4",
            "44bf1f44ff5b43af9d8e84cb2021a68e",
            "d20467ddcf704cf198358b3b4a877071",
            "e9d285d2ddd64108a454110df494c09d",
            "5f995553673148af8a737a5b6a1c5acf",
            "6829d18433524663b7d3eaef6a4cb912",
            "d107af9ea1e04c81b56e5c64b322900f",
            "fe21b8b5b9924c5eafbf34219f81500e",
            "7cb7554d9c874567a6941fab0bf11f6a",
            "a15f8a5c5d334556b2e1f0b484f61b15",
            "4ac7c292685e44738eaaafd4f96d1cf1",
            "cfd36c2a8f1d4a3ab4cb3ed39a65f437",
            "5923c76e6b40417bafcde1403313c912",
            "11be048a4839403081c461a28b5e5588",
            "b8c9edf970c8418fb7d9f69e9af7ad01",
            "8bf2e3952ec149ddb70462177efb101e",
            "f0ea4c887813477bb98f499c1dbc8299",
            "f2a548566c97444b88d6c677bf6d1e3a",
            "50a84358abf0403baf78de53e48a7471",
            "f21d66bb1d024923a2a217825f8f1d86",
            "e3bae37d151147fcaa60fc781ba00c59",
            "c75aee1cdb324f83929ba39060bb39ea",
            "4c2d1c34b5454d4284598a83333e700d",
            "71031b5d2bf3469b976662b842f3d0de",
            "0f6ee227aaf64581ab5547852a3deceb",
            "5d4d6ffc02034d979cca1c35b1c42cac",
            "c1f27f4edb9c436785b862179a612106",
            "94c2c707b2f64f41bfd1ed407f55d217",
            "daf4d5807a204d368f4ae0e105667ad0",
            "16448776c3c4478db7108ee4959adc6e",
            "3569b9e42387424a86f1667b9d332399",
            "81b142a75a9b42ffbaf5b83662369163",
            "e7dae35e4cff40228e690413aca646be",
            "a369f72d6a7d4c6e98da556aa50584ac",
            "059e23f299324784bce41105cb49b091",
            "41336a2d0e434f38893b1aab4b1b8b7b",
            "c294e9ffd5154f3caedcfbb84a729b7b",
            "2024f7d84ceb4942b96ea56d573a283d",
            "d5c54d07bb874dcd82fc31b7f675aa65",
            "cd54e3976eaf4784beada1054812d363",
            "055442f22abb4558879cb0483e1fff9e",
            "67726c8555d74cc283f67366f92bd589",
            "958403bdf96a4540a865c53f136cf953",
            "2cc9e943c57c4511a9f305e63720eae2",
            "a234aaed62b74084979745893aa262c5",
            "3703e721b4da460095bcb96778340fc6",
            "ca47783993ca43cea6488607a7acaaf7",
            "ee8d4f4c74744611819f638f08052ddc",
            "1bad74f32f864f50907aa4c22bd537a3",
            "57733555c6ac4d80a686ff361d1a3337",
            "8c798c2e1ef644478b4a1bb63d236e99",
            "6f51fae772a74f31aa4e3de6edd4ee20",
            "58d2f5f316f24f83b8b88318dff0e36b",
            "96ced339f1514e2eaab561fb0d4ecd15",
            "31903c5e93a947ca93330f15a30f038f",
            "23ce91110165403484e90b2ccdc392cb",
            "dd655121f9bd4739a267ae9cbdeb3dd1",
            "f923e4d3eee946e2a5c797d4ae2357a6",
            "6c1be214beef4e71b3b4f74e426b8ea5",
            "dd3ce6700d2d4f4e889c12d9622763bf",
            "034176114fab46678a52fba9a0fd28bd",
            "476822d28bc84841832ff18e0b810755",
            "e607b265d4904a3abc20863f45dfc2b9",
            "e24152aba6db4810b6e0bd33290e8178",
            "c2aed5dd865d470f8271bab7ad2d9097",
            "2bc1a94952b8417cb6f3f1d209f0fe65",
            "f28284552e9040d4b8517fa6990558fa",
            "b1b330029d1b408d9c9b8980d8367bbc"
          ]
        },
        "id": "q35RjnWqtdKb",
        "outputId": "d8ae345f-2bda-4bc3-b58c-fbbd4e4eff59"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "954ef74dd3ee461d9c1f343e49e6fcfc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5156 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2192d5e5c1343da992a5bdf99bff86b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/553 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=1 train_loss=0.6749 train_acc=0.5144 val_loss=0.6501 val_acc=0.5544\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d518172150784dbeb83d40c69a65995e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5156 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d5a7f19168346318659df519d2dfccc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/553 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=2 train_loss=0.6477 train_acc=0.5965 val_loss=0.6418 val_acc=0.6376\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d20467ddcf704cf198358b3b4a877071",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5156 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11be048a4839403081c461a28b5e5588",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/553 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=3 train_loss=0.6408 train_acc=0.6145 val_loss=0.6426 val_acc=0.6459\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f6ee227aaf64581ab5547852a3deceb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5156 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41336a2d0e434f38893b1aab4b1b8b7b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/553 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=4 train_loss=0.6356 train_acc=0.6270 val_loss=0.6360 val_acc=0.6376\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca47783993ca43cea6488607a7acaaf7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5156 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f923e4d3eee946e2a5c797d4ae2357a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/553 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=5 train_loss=0.6315 train_acc=0.6385 val_loss=0.6364 val_acc=0.6200\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    tr_loss, tr_acc = run_epoch_tqdm(model, train_loader, train=True)\n",
        "    va_loss, va_acc = run_epoch_tqdm(model, val_loader, train=False)\n",
        "\n",
        "    train_losses.append(tr_loss); train_accs.append(tr_acc)\n",
        "    val_losses.append(va_loss);   val_accs.append(va_acc)\n",
        "\n",
        "    print(f\"epoch={epoch} train_loss={tr_loss:.4f} train_acc={tr_acc:.4f} val_loss={va_loss:.4f} val_acc={va_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0crRL_gc99qo"
      },
      "source": [
        "epoch=1 train_loss=0.6749 train_acc=0.5144 val_loss=0.6501 val_acc=0.5544\n",
        "\n",
        "epoch=2 train_loss=0.6477 train_acc=0.5965 val_loss=0.6418 val_acc=0.6376\n",
        "\n",
        "epoch=3 train_loss=0.6408 train_acc=0.6145 val_loss=0.6426 val_acc=0.6459\n",
        "\n",
        "epoch=4 train_loss=0.6356 train_acc=0.6270 val_loss=0.6360 val_acc=0.6376\n",
        "\n",
        "epoch=5 train_loss=0.6315 train_acc=0.6385 val_loss=0.6364 val_acc=0.6200\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiKyPgRlN53I",
        "outputId": "61955763-d9c0-4348-ad70-b3e56bbc4121"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.4906    0.8083    0.6106      4371\n",
            "           2     0.2790    0.3356    0.3047      3424\n",
            "           3     0.3461    0.3760    0.3604      6982\n",
            "           4     0.3698    0.4994    0.4249     13261\n",
            "           5     0.8884    0.7057    0.7866     42666\n",
            "\n",
            "    accuracy                         0.6229     70704\n",
            "   macro avg     0.4748    0.5450    0.4974     70704\n",
            "weighted avg     0.6835    0.6229    0.6425     70704\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 3533   511   180    69    78]\n",
            " [ 1483  1149   571   172    49]\n",
            " [  953  1482  2625  1507   415]\n",
            " [  403   550  2446  6622  3240]\n",
            " [  829   426  1762  9539 30110]]\n",
            "MAE: 0.4994342625141144\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "all_true = []\n",
        "all_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xw, xc, lengths, y in test_loader:\n",
        "        xw, xc, lengths = xw.to(device), xc.to(device), lengths.to(device)\n",
        "\n",
        "        logits = model(xw, xc, lengths)\n",
        "        pred = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "\n",
        "        all_pred.append(pred)\n",
        "        all_true.append(y.numpy())\n",
        "\n",
        "y_true = np.concatenate(all_true) + 1\n",
        "y_pred = np.concatenate(all_pred) + 1\n",
        "\n",
        "print(classification_report(y_true, y_pred, digits=4))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "mae_torch = (torch.as_tensor(y_true) - torch.as_tensor(y_pred)).abs().float().mean().item()\n",
        "print(\"MAE:\", mae_torch)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}